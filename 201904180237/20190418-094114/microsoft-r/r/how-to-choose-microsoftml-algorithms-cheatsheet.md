<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="how-to-choose-microsoftml-algorithms-cheatsheet.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-d1654b2" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">20cd1eea-d819-421c-a8f6-e0e067dea9266d4f1438289fe56b0a76ef703141fd6a43a80f37.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">6d4f1438289fe56b0a76ef703141fd6a43a80f37</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">20cd1eea-d819-421c-a8f6-e0e067dea926</xliffext:ms.sourcegitcommit><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/18/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">microsoft-r\r\how-to-choose-microsoftml-algorithms-cheatsheet.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve" restype="x-metadata">
          <source>Cheat sheet: How to choose a MicrosoftML algorithm - Machine Learning Server</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve" restype="x-metadata">
          <source>A printable cheat sheet helps you choose a MicrosoftML package algorithm for a predictive model when using Machine Learning Server.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve" restype="x-metadata">
          <source>MicrosoftML</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Cheat sheet: How to choose a MicrosoftML algorithm</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>MicrosoftML: Algorithm Cheat Sheet<ept id="p1">**</ept> helps you choose the right machine learning algorithm for a predictive analytics model when using Machine Learning Server.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The algorithms are available in R or Python.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>MicrosoftML provides a library of algorithms from the  <bpt id="p1">***</bpt>regression<ept id="p1">***</ept>, <bpt id="p2">***</bpt>classification (two-class and multi-class)<ept id="p2">***</ept>, and <bpt id="p3">***</bpt>anomaly detection<ept id="p3">***</ept> families.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Each is designed to address a different type of machine learning problem.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Download the MicrosoftML Algorithm Cheat Sheet</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Download the cheat sheet here: <bpt id="p2">[</bpt>MicrosoftML Package: Algorithm Cheat Sheet v2 (11x17 in.)<ept id="p2">](https://go.microsoft.com/fwlink/?linkid=858939)</ept><ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>MicrosoftML: Algorithm Cheat Sheet: Learn how to choose a Machine Learning algorithm.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Download and print the <bpt id="p1">**</bpt>MicrosoftML: Algorithm Cheat Sheet<ept id="p1">**</ept> in tabloid size to keep it handy for guidance when choosing a machine learning algorithm.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>MicrosoftML machine learning algorithms</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>This section contains descriptions of the machine learning algorithms contained in the Algorithm Cheat Sheet.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The algorithms are available in R or Python.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The R And Python names are provided in the format: <ph id="ph1">`**R name/Python name**`</ph>.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Fast Linear model (SDCA)</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxFastTrees() / rx_fast_trees()`</ph><ept id="p1">**</ept> algorithm is based on the Stochastic Dual Coordinate Ascent (SDCA) method, a state-of-the-art optimization technique for convex objective functions.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The algorithm can be scaled for use on large out-of-memory data sets due to a semi-asynchronized implementation that supports multithreaded processing.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Several choices of loss functions are also provided and elastic net regularization is supported.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The SDCA method combines several of the best properties and capabilities of logistic regression and SVM algorithms.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary classification, linear regression</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>OneClass SVM</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxOneClassSvm() / rx_one_class_svm()`</ph><ept id="p1">**</ept> algorithm is used for one-class anomaly detection.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This is a type of unsupervised learning as its training set contains only examples from the target class and not any anomalous instances.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>It infers what properties are normal for the objects in the target class and from these properties predicts which examples are unlike these normal examples.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>This is useful as typically there are very few examples of network intrusion, fraud, or other types of anomalous behavior in training data sets.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: anomaly detection</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Fast Tree</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxFastTrees() / rx_fast_trees()`</ph><ept id="p1">**</ept> algorithm is a high performing, state of the art scalable boosted decision tree that implements FastRank, an efficient implementation of the MART gradient boosting algorithm.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>MART learns an ensemble of regression trees, which is a decision tree with scalar values in its leaves.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>For binary classification, the output is converted to a probability by using some form of calibration.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary classification, regression</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Fast Forest</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxFastForest() / rx_fast_forest()`</ph><ept id="p1">**</ept> algorithm is a random forest that provides a learning method for classification that constructs an ensemble of decision trees at training time, outputting the class that is the mode of the classes of the individual trees.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Random decision forests can correct for the overfitting to training data sets to which decision trees are prone.</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary classification, regression</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Neural Network</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxNeuralNet() / rx_neural_net()`</ph><ept id="p1">**</ept> algorithm supports a user-defined multilayer network topology with GPU acceleration.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>A neural network is a class of prediction models inspired by the human brain.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>It can be represented as a weighted directed graph.</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Each node in the graph is called a neuron.</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The neural network algorithm tries to learn the optimal weights on the edges based on the training data.</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Any class of statistical models can be considered a neural network if they use adaptive weights and can approximate non-linear functions of their inputs.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Neural network regression is especially suited to problems where a more traditional regression model cannot fit a solution.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary and multiclass classification, regression</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Logistic regression</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxLogisticRegression() / rx_logistic_regression()`</ph><ept id="p1">**</ept> algorithm is used to predict the value of a categorical dependent variable from its relationship to one or more independent variables assumed to have a logistic distribution.</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source>If the dependent variable has only two possible values (success/failure), then the logistic regression is binary.</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source>If the dependent variable has more than two possible values (blood type given diagnostic test results), then the logistic regression is multinomial.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary and multiclass classification</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Ensemble methods</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt><ph id="ph1">`rxEnsemble() / rx_emsemble()`</ph><ept id="p1">**</ept> algorithm uses a combination of learning algorithms to provide better predictive performance that the algorithms could individually.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The approach is used primarily in the Hadoop/Spark environment for training across a multi-node cluster.</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>But it can also be used in a single-node/local context.</source>
        </trans-unit><trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tasks supported<ept id="p1">**</ept>: binary and multiclass classification, regression</source>
        </trans-unit><trans-unit id="157" translate="yes" xml:space="preserve">
          <source>More help with algorithms</source>
        </trans-unit><trans-unit id="158" translate="yes" xml:space="preserve">
          <source>For a list by category of all the machine learning algorithms available in the MicrosoftML package, see:</source>
        </trans-unit><trans-unit id="159" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>MicrosoftML R functions<ept id="p1">](../r-reference/microsoftml/microsoftml-package.md)</ept></source>
        </trans-unit><trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>MicrosoftML Python functions<ept id="p1">](../python-reference/microsoftml/microsoftml-package.md)</ept></source>
        </trans-unit><trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Notes and terminology definitions for the machine learning algorithm cheat sheet</source>
        </trans-unit><trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The suggestions offered in this algorithm cheat sheet are approximate rules-of-thumb.</source>
        </trans-unit><trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Some can be bent and some can be flagrantly violated.</source>
        </trans-unit><trans-unit id="164" translate="yes" xml:space="preserve">
          <source>This sheet is only intended to suggest a starting point.</source>
        </trans-unit><trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Donâ€™t be afraid to run a head-to-head competition between several algorithms on your data.</source>
        </trans-unit><trans-unit id="166" translate="yes" xml:space="preserve">
          <source>There is simply no substitute for understanding the principles of each algorithm and understanding the system that generated your data.</source>
        </trans-unit><trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Every machine learning algorithm has its own style or <bpt id="p1">*</bpt>inductive bias<ept id="p1">*</ept>.</source>
        </trans-unit><trans-unit id="168" translate="yes" xml:space="preserve">
          <source>For a specific problem, several algorithms may be appropriate and one algorithm may be a better fit than others.</source>
        </trans-unit><trans-unit id="169" translate="yes" xml:space="preserve">
          <source>But anticipating which will be the best fit beforehand is not always possible.</source>
        </trans-unit><trans-unit id="170" translate="yes" xml:space="preserve">
          <source>In cases like these, several algorithms are listed together in the cheat sheet.</source>
        </trans-unit><trans-unit id="171" translate="yes" xml:space="preserve">
          <source>An appropriate strategy would be to try one algorithm, and if the results are not yet satisfactory, try the others.</source>
        </trans-unit><trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Two categories of machine learning are supported by MicrosoftML: <bpt id="p1">**</bpt>supervised learning<ept id="p1">**</ept> and <bpt id="p2">**</bpt>unsupervised learning<ept id="p2">**</ept>.</source>
        </trans-unit><trans-unit id="173" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">**</bpt>supervised learning<ept id="p1">**</ept>, each data point is labeled or associated with a category or value of interest.</source>
        </trans-unit><trans-unit id="174" translate="yes" xml:space="preserve">
          <source>The goal of supervised learning is to study many labeled examples like these, and then to be able to make predictions about future data points.</source>
        </trans-unit><trans-unit id="175" translate="yes" xml:space="preserve">
          <source>All of the algorithms in MicrosoftML are supervised learners except <ph id="ph1">`rxOneClassSvm()`</ph> used for anomaly detection.</source>
        </trans-unit><trans-unit id="176" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">**</bpt>unsupervised learning<ept id="p1">**</ept>, data points have no labels associated with them.</source>
        </trans-unit><trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Instead, the goal of an unsupervised learning algorithm is to organize the data in some way or to describe its structure.</source>
        </trans-unit><trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Only the <ph id="ph1">`rxOneClassSvm()`</ph> algorithm used for anomaly detection is an unsupervised learner.</source>
        </trans-unit><trans-unit id="179" translate="yes" xml:space="preserve">
          <source>What's next?</source>
        </trans-unit><trans-unit id="180" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Quickstarts for MicrosoftML<ept id="p1">](sample-microsoftml.md)</ept> shows how to use pre-trained models for sentiment analysis and image featurization.</source>
        </trans-unit></group></body></file></xliff>